{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2704339a-cede-481f-9981-85b58648ec33",
   "metadata": {},
   "source": [
    "# **Implementing a Matrix Factorization-based Recommender System**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5bca0-4c95-4c78-bff5-32a8c7d3ae8c",
   "metadata": {},
   "source": [
    "## **Represent user and item by Matrix Factorization**\n",
    " - Users and items are represented through matrix factorization.\r",
    "  - A user-item interaction matrix$( R \\in \\mathbb{R}^{n \\times m}$) is approximated as the product of two matrices:$( R \\approx P \\times Q$), where$( P \\in \\mathbb{R}^{n \\times d}$) and$( Q \\in \\mathbb{R}^{m \\times d}$).\n",
    "  - $ n $ is the number of users, $ m $ is the number of items, and $ d $ is the dimension of the embedding vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d7e68-600a-4ba7-bb48-d114dbe140a9",
   "metadata": {},
   "source": [
    "**How to do Matrix Factorization**:\n",
    "   - The goal is to find a good representation for users and items.\n",
    "   - The objective is to minimize the differences between the predicted and actual interaction values: $ \\min_{P,Q} \\sum_{(u,i) \\in R'} (r_{ui} - P_u Q_i)^2 $.\n",
    "   - Not all elements in $ R $ are known; $ R' $ is the set of known elements in $ R $.\n",
    "   - $ r_{ui} $ is the interaction record of user $ u $ and item $ i $.\n",
    "   - $ P_u $ is the embedding vector for user $ u $, and $ Q_i $ is the embedding vector for item $ i $.\n",
    "   - The interaction probability between user $ u $ and item $ i $ is $ r_{ui} = P_u Q_i $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951aa1f6-e071-458f-9c09-787f68046790",
   "metadata": {},
   "source": [
    "## **Requirements:**\n",
    "In this practice, you will implement a recommender system using **Matrix Factorization**.\n",
    "You should:\n",
    "   - Construct a matrix factorization-based recommender system using the positive data `train_pos.npy` provided in project 3.\n",
    "   - For each user-item pair $ u, i $ in `train_pos.npy`, $ R_{ui} = 1 $.\n",
    "   - If a user-item pair $ u^*, i^* $ is not in `train_pos.npy`, $ R_{u^*i^*} = 0 $.\n",
    "   - The task is to find a good embedding representation for each user and item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7db510-0871-4966-8f47-87c9eec9c3a3",
   "metadata": {},
   "source": [
    "\n",
    "## **Reference Workflow**:\n",
    "   1. Load the data and construct an interaction matrix.\n",
    "   2. Obtain the embedding representation for each user and item.\n",
    "      - **Use the objective function above and optimize the embeddings via gradient descent.**\n",
    "      - **Note: The number of negative samples is much larger than that of positive samples. You can sample some negative samples in each iteration instead of using all negative samples.**\n",
    "   3. Validate the effectiveness of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132b701-8062-4a2d-a692-92a4eb717b39",
   "metadata": {},
   "source": [
    "### **Deadline:** 22:00, Dec. 20th\n",
    "\n",
    "The practice will be checked in this lab class or the next lab class (before **Dec. 20th**) by teachers or SAs.\n",
    "\n",
    "### **Grading:**\n",
    "* Submissions in this lab class: 1.1 points.\n",
    "* Submissions on time: 1 point.\n",
    "* Late submissions within 2 weeks after the deadline: 0.8 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c778e74-ac83-43b2-b32b-ce131fce6331",
   "metadata": {},
   "source": [
    "## **1 Load and Explore the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b00122-8884-41ac-9031-ef64d73791c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40540,\n",
       " array([[3078,  480,    0],\n",
       "        [4097, 2045,    1],\n",
       "        [2245, 1214,    1],\n",
       "        [5984,   83,    1],\n",
       "        [ 835, 1528,    1]]),\n",
       " array([[5712,  756,    1],\n",
       "        [4540,  624,    1],\n",
       "        [3012, 1655,    1],\n",
       "        [5172,  623,    1],\n",
       "        [4890,   73,    0]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "train_pos = np.load(\"train_pos.npy\")  # Contains user-item pairs\n",
    "train_neg = np.load(\"train_neg.npy\")\n",
    "data_set = np.concatenate((train_pos, train_neg), axis=0)\n",
    "\n",
    "train_set, test_set = train_test_split(data_set, test_size=0.2)\n",
    "\n",
    "users, items = set(train_set[:, 0]), set(train_set[:, 1])\n",
    "len(train_set),train_set[:5],train_set[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62482f2-d273-4248-b8ff-3a1d8526774c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(6015), np.int64(2347))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_user, n_item = max(users) + 1, max(items) + 1\n",
    "n_user, n_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe0038-40f9-4100-aef0-1a7438e3d31d",
   "metadata": {},
   "source": [
    "## **2. Initialize Parameters**\n",
    "\n",
    "Initialize the embedding matrices $P$ for users and $Q$ for items. These matrices represent the user and item embeddings.\n",
    "\n",
    "**Fill in the missing parts:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d7dfc6-5f30-42f3-b1e8-cf64a9ae4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding dimension\n",
    "dim = 60 # Specify the embedding dimension\n",
    "\n",
    "# Initialize user and item embeddings with random values\n",
    "P = np.random.normal(0, 0.1, (n_user, dim)) # Fill in the correct dimensions for user embeddings\n",
    "Q = np.random.normal(0, 0.1, (n_item, dim)) # Fill in the correct dimensions for item embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498092a6-24e8-4f09-8f7c-93df437d9aaa",
   "metadata": {},
   "source": [
    "## **3. Optimize the embeddings via gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390e1f4-ef1d-487c-9cb0-e038874d43d9",
   "metadata": {},
   "source": [
    "The loss function to optimize is Mean Squared Error (MSE):\n",
    "$$\n",
    "\\text{Loss} = \\sum_{(u, i) \\in R'} (r_{ui} - P_u Q_i^T)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0822f-1a4b-4b41-9dd8-af844f2ac02d",
   "metadata": {},
   "source": [
    "OR add the regularization term:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\sum_{(u, i) \\in R'} (r_{ui} - P_u Q_i^T)^2 + \\lambda (\\|P_u\\|^2 + \\|Q_i\\|^2)\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $ ùëÖ' $ is the set of the known elements in the $ ùëÖ $\n",
    "- $ r_{ui} $ is 1 for positive samples and 0 for negative samples.\n",
    "- $ \\lambda $ is the regularization term to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba630e8-51ec-42fb-a481-27bb4580ecc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 19432.895551602112\n",
      "Epoch 2/50, Loss: 18845.574380311184\n",
      "Epoch 3/50, Loss: 18219.315828391114\n",
      "Epoch 4/50, Loss: 17524.044926835617\n",
      "Epoch 5/50, Loss: 16734.53790339138\n",
      "Epoch 6/50, Loss: 15836.13013532999\n",
      "Epoch 7/50, Loss: 14833.060667848247\n",
      "Epoch 8/50, Loss: 13753.85477155113\n",
      "Epoch 9/50, Loss: 12646.769910965395\n",
      "Epoch 10/50, Loss: 11565.074070008994\n",
      "Epoch 11/50, Loss: 10551.401357834862\n",
      "Epoch 12/50, Loss: 9630.342939875103\n",
      "Epoch 13/50, Loss: 8809.904508614358\n",
      "Epoch 14/50, Loss: 8086.9857785959375\n",
      "Epoch 15/50, Loss: 7452.770637519291\n",
      "Epoch 16/50, Loss: 6896.466122267638\n",
      "Epoch 17/50, Loss: 6407.389427941055\n",
      "Epoch 18/50, Loss: 5975.903529751986\n",
      "Epoch 19/50, Loss: 5593.697545715765\n",
      "Epoch 20/50, Loss: 5253.75389338209\n",
      "Epoch 21/50, Loss: 4950.19539554227\n",
      "Epoch 22/50, Loss: 4678.105838934916\n",
      "Epoch 23/50, Loss: 4433.362684654174\n",
      "Epoch 24/50, Loss: 4212.494280012529\n",
      "Epoch 25/50, Loss: 4012.562641089311\n",
      "Epoch 26/50, Loss: 3831.068761654539\n",
      "Epoch 27/50, Loss: 3665.8764355294466\n",
      "Epoch 28/50, Loss: 3515.1508481978076\n",
      "Epoch 29/50, Loss: 3377.3088372846287\n",
      "Epoch 30/50, Loss: 3250.9783811042535\n",
      "Epoch 31/50, Loss: 3134.96542750095\n",
      "Epoch 32/50, Loss: 3028.226602878647\n",
      "Epoch 33/50, Loss: 2929.8466624264397\n",
      "Epoch 34/50, Loss: 2839.0197833681577\n",
      "Epoch 35/50, Loss: 2755.033986138548\n",
      "Epoch 36/50, Loss: 2677.258110099986\n",
      "Epoch 37/50, Loss: 2605.1308818758794\n",
      "Epoch 38/50, Loss: 2538.1517030282416\n",
      "Epoch 39/50, Loss: 2475.8728547861224\n",
      "Epoch 40/50, Loss: 2417.892874539105\n",
      "Epoch 41/50, Loss: 2363.850904667231\n",
      "Epoch 42/50, Loss: 2313.4218511932577\n",
      "Epoch 43/50, Loss: 2266.3122194854823\n",
      "Epoch 44/50, Loss: 2222.2565182304425\n",
      "Epoch 45/50, Loss: 2181.0141422765037\n",
      "Epoch 46/50, Loss: 2142.3666606411603\n",
      "Epoch 47/50, Loss: 2106.1154487024874\n",
      "Epoch 48/50, Loss: 2072.079613949216\n",
      "Epoch 49/50, Loss: 2040.0941731047387\n",
      "Epoch 50/50, Loss: 2010.0084453415761\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "learning_rate = 1e-2\n",
    "num_epochs = 50\n",
    "reg = 0.1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for user, item, rating in train_set:\n",
    "        pred = np.dot(P[user], Q[item])\n",
    "        error = rating - pred\n",
    "        grad_P = -2 * error * Q[item] + 2 * reg * P[user]\n",
    "        grad_Q = -2 * error * P[user] + 2 * reg * Q[item]\n",
    "        P[user] -= learning_rate * grad_P\n",
    "        Q[item] -= learning_rate * grad_Q\n",
    "        total_loss += error ** 2\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a00c5-41e2-4c05-afbe-e03bee01a148",
   "metadata": {},
   "source": [
    "## **4 Verification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0075303-6879-45a7-a74e-59aa5a9b0b60",
   "metadata": {},
   "source": [
    "Choose an appropriate metric to evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a61bfa57-f97d-43fb-8173-c0950c806ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2783396620906268\n",
      "Accuracy: 0.635027133695116\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "def calculate_mse(data, P, Q):\n",
    "    mse = 0\n",
    "    for user, item, rating in data:\n",
    "        pred = np.dot(P[user], Q[item])\n",
    "        mse += (rating - pred) ** 2\n",
    "    return mse / len(data)\n",
    "\n",
    "# Calculate MSE for the training data\n",
    "train_mse = calculate_mse(test_set, P, Q)\n",
    "print(f\"MSE: {train_mse}\")\n",
    "\n",
    "def predict(user, item):\n",
    "    return np.dot(P[user], Q[item])\n",
    "\n",
    "accurate = 0\n",
    "for user, item, rating in test_set:\n",
    "    result = predict(user, item)\n",
    "    accurate += int(abs(result - rating) < 0.5)\n",
    "\n",
    "print(f\"Accuracy: {accurate / len(test_set)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
